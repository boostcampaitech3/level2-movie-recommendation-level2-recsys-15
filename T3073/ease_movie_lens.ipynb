{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EASE\n",
    "\n",
    "* 출처: [TorchEASE](https://github.com/franckjay/TorchEASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import logging\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class TorchEASE:\n",
    "    def __init__(\n",
    "        self, train, user_col=\"user_id\", item_col=\"item_id\", score_col=None, reg=250.0\n",
    "    ):\n",
    "        \"\"\"\n",
    "        :param train: Training DataFrame of user, item, score(optional) values\n",
    "        :param user_col: Column name for users\n",
    "        :param item_col: Column name for items\n",
    "        :param score_col: Column name for scores. Implicit feedback otherwise\n",
    "        :param reg: Regularization parameter.\n",
    "                    Change by orders of magnitude to tune (2e1, 2e2, ...,2e4)\n",
    "        \"\"\"\n",
    "        logging.basicConfig(\n",
    "            format=\"%(asctime)s [%(levelname)s] %(name)s - %(message)s\",\n",
    "            level=logging.INFO,\n",
    "            datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    "            stream=sys.stdout,\n",
    "        )\n",
    "\n",
    "        self.logger = logging.getLogger(\"notebook\")\n",
    "        self.logger.info(\"Building user + item lookup\")\n",
    "        # How much regularization do you need?\n",
    "        self.reg = reg\n",
    "\n",
    "        self.user_col = user_col\n",
    "        self.item_col = item_col\n",
    "\n",
    "        self.user_id_col = user_col + \"_id\"\n",
    "        self.item_id_col = item_col + \"_id\"\n",
    "\n",
    "        self.user_lookup = self.generate_labels(train, self.user_col)\n",
    "        self.item_lookup = self.generate_labels(train, self.item_col)\n",
    "\n",
    "        self.item_map = {}\n",
    "        self.logger.info(\"Building item hashmap\")\n",
    "        for _item, _item_id in self.item_lookup.values:\n",
    "            self.item_map[_item_id] = _item\n",
    "\n",
    "        train = pd.merge(train, self.user_lookup, on=[self.user_col])\n",
    "        train = pd.merge(train, self.item_lookup, on=[self.item_col])\n",
    "        self.logger.info(\"User + item lookup complete\")\n",
    "        self.indices = torch.LongTensor(\n",
    "            train[[self.user_id_col, self.item_id_col]].values\n",
    "        )\n",
    "\n",
    "        if not score_col:\n",
    "            # Implicit values only\n",
    "            self.values = torch.ones(self.indices.shape[0])\n",
    "        else:\n",
    "            # TODO: Test if score_col works correctly\n",
    "            self.values = torch.FloatTensor(train[score_col])\n",
    "\n",
    "        # TODO: Is Sparse the best implementation?\n",
    "        self.sparse = torch.sparse.FloatTensor(self.indices.t(), self.values)\n",
    "\n",
    "        self.logger.info(\"Sparse data built\")\n",
    "\n",
    "    def generate_labels(self, df, col):\n",
    "        dist_labels = df[[col]].drop_duplicates()\n",
    "        dist_labels[col + \"_id\"] = dist_labels[col].astype(\"category\").cat.codes\n",
    "\n",
    "        return dist_labels\n",
    "\n",
    "    def fit(self):\n",
    "        self.logger.info(\"Building G Matrix\")\n",
    "        G = self.sparse.to_dense().t() @ self.sparse.to_dense()\n",
    "        G += torch.eye(G.shape[0]) * self.reg\n",
    "\n",
    "        P = G.inverse()\n",
    "\n",
    "        self.logger.info(\"Building B matrix\")\n",
    "        B = P / (-1 * P.diag())\n",
    "        # Set diagonals to 0. TODO: Use .fill_diag_\n",
    "        B = B + torch.eye(B.shape[0])\n",
    "\n",
    "        # Predictions for user `_u` will be self.sparse.to_dense()[_u]@self.B\n",
    "        self.B = B\n",
    "\n",
    "        return\n",
    "\n",
    "    def predict_all(self, pred_df, k=5, remove_owned=True):\n",
    "        \"\"\"\n",
    "        :param pred_df: DataFrame of users that need predictions\n",
    "        :param k: Number of items to recommend to each user\n",
    "        :param remove_owned: Do you want previously interacted items included?\n",
    "        :return: DataFrame of users + their predictions in sorted order\n",
    "        \"\"\"\n",
    "        pred_df = pred_df[[self.user_col]].drop_duplicates()\n",
    "        n_orig = pred_df.shape[0]\n",
    "\n",
    "        # Alert to number of dropped users in prediction set\n",
    "        pred_df = pd.merge(pred_df, self.user_lookup, on=[self.user_col])\n",
    "        n_curr = pred_df.shape[0]\n",
    "        if n_orig - n_curr:\n",
    "            self.logger.info(\n",
    "                \"Number of unknown users from prediction data = %i\" % (n_orig - n_curr)\n",
    "            )\n",
    "\n",
    "        _output_preds = []\n",
    "        # Select only user_ids in our user data\n",
    "        _user_tensor = self.sparse.to_dense().index_select(\n",
    "            dim=0, index=torch.LongTensor(pred_df[self.user_id_col])\n",
    "        )\n",
    "\n",
    "        # Make our (raw) predictions\n",
    "        _preds_tensor = _user_tensor @ self.B\n",
    "        self.logger.info(\"Predictions are made\")\n",
    "        if remove_owned:\n",
    "            # Discount these items by a large factor (much faster than list comp.)\n",
    "            self.logger.info(\"Removing owned items\")\n",
    "            _preds_tensor += -2.0 * _user_tensor\n",
    "\n",
    "        self.logger.info(\"TopK selected per user\")\n",
    "        for _preds in _preds_tensor:\n",
    "            # Very quick to use .topk() vs. argmax()\n",
    "            _output_preds.append(\n",
    "                [self.item_map[_id] for _id in _preds.topk(k).indices.tolist()]\n",
    "            )\n",
    "\n",
    "        pred_df[\"predicted_items\"] = _output_preds\n",
    "        self.logger.info(\"Predictions are returned to user\")\n",
    "        return pred_df\n",
    "\n",
    "    def score_predictions(self):\n",
    "        # TODO: Implement this with some common metrics\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hit_rate_k(pred_df, actual_col=\"item_id\", pred_col=\"predictions\"):\n",
    "    \"\"\"\n",
    "    :param pred_df: DataFrame containing what a user actually interacted with and a predicted list\n",
    "    :param actual_col: Column that has what the user actually engaged in\n",
    "    :param pred_col: Column name that has the predictions in list form\n",
    "    :return: Fractional hit rate for any predictions in `pred_col`\n",
    "    \"\"\"\n",
    "\n",
    "    pred_df[\"hit\"] = [\n",
    "        actual in pred for pred, actual in pred_df[[pred_col, actual_col]].values\n",
    "    ]\n",
    "\n",
    "    return pred_df[\"hit\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s [%(levelname)s] %(name)s - %(message)s\",\n",
    "    level=logging.INFO,\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    "    stream=sys.stdout,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(\"notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('/opt/ml/input/data/train/train_ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniq_user, unique_item = np.unique(train_df['user']), np.unique(train_df['item'])\n",
    "# uniq_user = np.repeat(uniq_user,len(unique_item))\n",
    "# unique_item = np.repeat(unique_item.reshape(1,-1),train_df['user'].nunique(),axis=0).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31360/31360 [00:04<00:00, 7747.14it/s]\n"
     ]
    }
   ],
   "source": [
    "watched = {}\n",
    "for name, g in tqdm(train_df.groupby('user')['item']):\n",
    "    watched[name] = set(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31360/31360 [00:21<00:00, 1473.96it/s]\n"
     ]
    }
   ],
   "source": [
    "users = []\n",
    "items = []\n",
    "total_item = set(unique_item)\n",
    "for user in tqdm(uniq_user):\n",
    "    users += [user] * len(total_item - watched[user])\n",
    "    items += list(total_item - watched[user])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = np.array(users)\n",
    "items = np.array(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame({'user':users,\n",
    "                        'item':items})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208313044</th>\n",
       "      <td>138493</td>\n",
       "      <td>32743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208313045</th>\n",
       "      <td>138493</td>\n",
       "      <td>49130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208313046</th>\n",
       "      <td>138493</td>\n",
       "      <td>65514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208313047</th>\n",
       "      <td>138493</td>\n",
       "      <td>49132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208313048</th>\n",
       "      <td>138493</td>\n",
       "      <td>81910</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>208313049 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             user   item\n",
       "0              11      2\n",
       "1              11      3\n",
       "2              11      4\n",
       "3              11      5\n",
       "4              11      6\n",
       "...           ...    ...\n",
       "208313044  138493  32743\n",
       "208313045  138493  49130\n",
       "208313046  138493  65514\n",
       "208313047  138493  49132\n",
       "208313048  138493  81910\n",
       "\n",
       "[208313049 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-11 09:14:35 [INFO] notebook - Training model\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Training model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-11 09:14:37 [INFO] notebook - Building user + item lookup\n",
      "2022-04-11 09:14:37 [INFO] notebook - Building item hashmap\n",
      "2022-04-11 09:14:38 [INFO] notebook - User + item lookup complete\n",
      "2022-04-11 09:14:38 [INFO] notebook - Sparse data built\n"
     ]
    }
   ],
   "source": [
    "te = TorchEASE(train_df, user_col='user',item_col='item',score_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-11 09:14:40 [INFO] notebook - Building G Matrix\n",
      "2022-04-11 09:14:50 [INFO] notebook - Building B matrix\n"
     ]
    }
   ],
   "source": [
    "te.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-11 09:14:52 [INFO] notebook - Making predictions\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Making predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-11 09:15:06 [INFO] notebook - Predictions are made\n",
      "2022-04-11 09:15:06 [INFO] notebook - Removing owned items\n",
      "2022-04-11 09:15:06 [INFO] notebook - TopK selected per user\n",
      "2022-04-11 09:15:07 [INFO] notebook - Predictions are returned to user\n"
     ]
    }
   ],
   "source": [
    "output = te.predict_all(pred_df, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31360/31360 [00:00<00:00, 673804.48it/s]\n"
     ]
    }
   ],
   "source": [
    "output_csv_user = []\n",
    "output_csv_item = []\n",
    "\n",
    "for user, predicted_items in tqdm(zip(output['user'],output['predicted_items']), total = len(output)):\n",
    "    output_csv_user += [user] * 10\n",
    "    output_csv_item += predicted_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_csv = pd.DataFrame({'user': output_csv_user, 'item': output_csv_item})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_csv.to_csv('ease_output.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
