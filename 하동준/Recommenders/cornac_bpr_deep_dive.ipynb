{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Copyright (c) Microsoft Corporation. All rights reserved.</i>\n",
    "\n",
    "<i>Licensed under the MIT License.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Personalized Ranking (BPR)\n",
    "\n",
    "This notebook serves as an introduction to Bayesian Personalized Ranking (BPR) model for implicit feedback.  In this tutorial, we focus on learning the BPR model using matrix factorization approach, hence, the model is sometimes also named BPRMF.\n",
    "\n",
    "The implementation of the model is from [Cornac](https://github.com/PreferredAI/cornac), which is a framework for recommender systems with a focus on models leveraging auxiliary data (e.g., item descriptive text and image, social network, etc)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 Global Settings and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System version: 3.8.5 (default, Sep  4 2020, 07:30:14) \n",
      "[GCC 7.3.0]\n",
      "Cornac version: 1.14.2\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import cornac\n",
    "import papermill as pm\n",
    "import scrapbook as sb\n",
    "import pandas as pd\n",
    "from recommenders.datasets import movielens\n",
    "from recommenders.datasets.python_splitters import python_random_split\n",
    "from recommenders.evaluation.python_evaluation import map_at_k, ndcg_at_k, precision_at_k, recall_at_k\n",
    "from recommenders.models.cornac.cornac_utils import predict_ranking\n",
    "from recommenders.utils.timer import Timer\n",
    "from recommenders.utils.constants import SEED\n",
    "\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"Cornac version: {}\".format(cornac.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Select MovieLens data size: 100k, 1m, 10m, or 20m\n",
    "MOVIELENS_DATA_SIZE = '100k'\n",
    "\n",
    "# top k items to recommend\n",
    "TOP_K = 10\n",
    "\n",
    "# Model parameters\n",
    "NUM_FACTORS = 200\n",
    "NUM_EPOCHS = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 BPR Algorithm\n",
    "\n",
    "### 1.1 Personalized Ranking from Implicit Feedback\n",
    "\n",
    "The task of personalized ranking aims at providing each user a ranked list of items (recommendations).  This is very common in scenarios where recommender systems are based on implicit user behavior (e.g. purchases, clicks).  The available observations are only positive feedback where the non-observed ones are a mixture of real negative feedback and missing values.\n",
    "\n",
    "One usual approach for item recommendation is directly predicting a preference score $\\hat{x}_{u,i}$ given to item $i$ by user $u$.  BPR uses a different approach by using item pairs $(i, j)$ and optimizing for the correct ranking given preference of user $u$, thus, there are notions of *positive* and *negative* items.  The training data $D_S : U \\times I \\times I$ is defined as:\n",
    "\n",
    "$$D_S = \\{(u, i, j) \\mid i \\in I^{+}_{u} \\wedge j \\in I \\setminus I^{+}_{u}\\}$$\n",
    "\n",
    "where user $u$ is assumed to prefer $i$ over $j$ (i.e. $i$ is a *positive item* and $j$ is a *negative item*).\n",
    "\n",
    "\n",
    "### 1.2 Objective Function\n",
    "\n",
    "From the Bayesian perspective, BPR maximizes the posterior probability over the model parameters $\\Theta$ by optimizing the likelihood function $p(i >_{u} j | \\Theta)$ and the prior probability $p(\\Theta)$.\n",
    "\n",
    "$$p(\\Theta \\mid >_{u}) \\propto p(i >_{u} j \\mid \\Theta) \\times p(\\Theta)$$\n",
    "\n",
    "The joint probability of the likelihood over all users $u \\in U$ can be simplified to:\n",
    "\n",
    "$$ \\prod_{u \\in U} p(>_{u} \\mid \\Theta) = \\prod_{(u, i, j) \\in D_S} p(i >_{u} j \\mid \\Theta) $$\n",
    "\n",
    "The individual probability that a user $u$ prefers item $i$ to item $j$ can be defined as:\n",
    "\n",
    "$$ p(i >_{u} j \\mid \\Theta) = \\sigma (\\hat{x}_{uij}(\\Theta)) $$\n",
    "\n",
    "where $\\sigma$ is the logistic sigmoid:\n",
    "\n",
    "$$ \\sigma(x) = \\frac{1}{1 + e^{-x}} $$\n",
    "\n",
    "The preference scoring function $\\hat{x}_{uij}(\\Theta)$ could be an arbitrary real-valued function of the model parameter $\\Theta$.  Thus, it makes BPR a general framework for modeling the relationship between triplets $(u, i, j)$ where different model classes like matrix factorization could be used for estimating $\\hat{x}_{uij}(\\Theta)$.\n",
    "\n",
    "For the prior, one of the common pratices is to choose $p(\\Theta)$ following a normal distribution, which results in a nice form of L2 regularization in the final log-form of the objective function.\n",
    "\n",
    "$$ p(\\Theta) \\sim N(0, \\Sigma_{\\Theta}) $$\n",
    "\n",
    "To reduce the complexity of the model, all parameters $\\Theta$ are assumed to be independent and having the same variance, which gives a simpler form of the co-variance matrix $\\Sigma_{\\Theta} = \\lambda_{\\Theta}I$.  Thus, there are less number of hyperparameters to be determined.\n",
    "\n",
    "The final objective of the maximum posterior estimator:\n",
    "\n",
    "$$ J = \\sum_{(u, i, j) \\in D_S} \\text{ln } \\sigma(\\hat{x}_{uij}) - \\lambda_{\\Theta} ||\\Theta||^2 $$\n",
    "\n",
    "where $\\lambda_\\Theta$ are the model specific regularization paramerters.\n",
    "\n",
    "\n",
    "### 1.3 Learning with Matrix Factorization\n",
    "\n",
    "#### Stochastic Gradient Descent\n",
    "\n",
    "As the defined objective function is differentible, gradient descent based method for optimization is naturally adopted.  The gradient of the objective $J$ with respect to the model parameters:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial J}{\\partial \\Theta} & = \\sum_{(u, i, j) \\in D_S} \\frac{\\partial}{\\partial \\Theta} \\text{ln} \\ \\sigma(\\hat{x}_{uij}) - \\lambda_{\\Theta} \\frac{\\partial}{\\partial \\Theta} ||\\Theta||^2 \\\\\n",
    "& \\propto \\sum_{(u, i, j) \\in D_S} \\frac{-e^{-\\hat{x}_{uij}}}{1 + e^{-\\hat{x}_{uij}}} \\cdot  \\frac{\\partial}{\\partial \\Theta} \\hat{x}_{uij} - \\lambda_{\\Theta} \\Theta\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Due to slow convergence of full gradient descent, we prefer using stochastic gradient descent to optimize the BPR model.  For each triplet $(u, i, j) \\in D_S$, the update rule for the parameters:\n",
    "\n",
    "$$ \\Theta \\leftarrow \\Theta + \\alpha \\Big( \\frac{e^{-\\hat{x}_{uij}}}{1 + e^{-\\hat{x}_{uij}}} \\cdot \\frac{\\partial}{\\partial \\Theta} \\hat{x}_{uij} + \\lambda_\\Theta \\Theta \\Big) $$\n",
    "\n",
    "#### Matrix Factorization for Preference Approximation\n",
    "\n",
    "As mentioned earlier, the preference scoring function $\\hat{x}_{uij}(\\Theta)$ could be approximated by any real-valued function.  First, the estimator $\\hat{x}_{uij}$ is decomposed into:\n",
    "\n",
    "$$ \\hat{x}_{uij} = \\hat{x}_{ui} - \\hat{x}_{uj} $$\n",
    "\n",
    "The problem of estimating $\\hat{x}_{ui}$ is a standard collaborative filtering formulation, where matrix factorization approach has shown to be very effective.  The prediction formula can written as dot product between user feature vector $w_u$ and item feature vector $h_i$:\n",
    "\n",
    "$$ \\hat{x}_{ui} = \\langle w_u , h_i \\rangle = \\sum_{f=1}^{k} w_{uf} \\cdot h_{if} $$\n",
    "\n",
    "The  derivatives of matrix factorization with respect to the model parameters are:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial}{\\partial \\theta} \\hat{x}_{uij} = \n",
    "\\begin{cases}\n",
    "    (h_{if} - h_{jf})  & \\text{if } \\theta = w_{uf} \\\\\n",
    "    w_{uf}             & \\text{if } \\theta = h_{if} \\\\\n",
    "    -w_{uf}            & \\text{if } \\theta = h_{jf} \\\\\n",
    "    0                  & \\text{else}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "In theory, any kernel can be used to estimate $\\hat{x}_{ui}$ besides the dot product $ \\langle \\cdot , \\cdot \\rangle $.  For example, k-Nearest-Neighbor (kNN) has also been shown to achieve good performance.\n",
    "\n",
    "#### Analogies to AUC optimization\n",
    "\n",
    "By optimizing the objective function of BPR model, we effectively maximizing [AUC](https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5) measurement.  To keep the notebook focused, please refer to the [paper](https://arxiv.org/ftp/arxiv/papers/1205/1205.2618.pdf) for details of the analysis (Section 4.1.1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Cornac implementation of BPR\n",
    "\n",
    "BPR is implemented in the [Cornac](https://cornac.readthedocs.io/en/latest/index.html) framework as part of the model collections.\n",
    "* Detailed documentations of the BPR model in Cornac can be found [here](https://cornac.readthedocs.io/en/latest/models.html#bayesian-personalized-ranking-bpr).\n",
    "* Source codes of the BPR implementation is available on the Cornac Github repository, which can be found [here](https://github.com/PreferredAI/cornac/blob/master/cornac/models/bpr/recom_bpr.pyx).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Cornac BPR movie recommender\n",
    "\n",
    "\n",
    "### 3.1 Load and split data\n",
    "\n",
    "To evaluate the performance of item recommendation, we adopted the provided `python_random_split` tool for the consistency.  Data is randomly split into training and test sets with the ratio of 75/25.\n",
    "\n",
    "\n",
    "Note that Cornac also cover different [built-in schemes](https://cornac.readthedocs.io/en/latest/eval_methods.html) for model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████| 4.81k/4.81k [00:08<00:00, 590KB/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  itemID  rating\n",
       "0     196     242     3.0\n",
       "1     186     302     3.0\n",
       "2      22     377     1.0\n",
       "3     244      51     2.0\n",
       "4     166     346     1.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = movielens.load_pandas_df(\n",
    "    size=MOVIELENS_DATA_SIZE,\n",
    "    header=[\"userID\", \"itemID\", \"rating\"]\n",
    ")\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw rating df\n",
      "           user   item  rating\n",
      "0            11   4643     1.0\n",
      "1            11    170     1.0\n",
      "2            11    531     1.0\n",
      "3            11    616     1.0\n",
      "4            11   2140     1.0\n",
      "...         ...    ...     ...\n",
      "5154466  138493  44022     1.0\n",
      "5154467  138493   4958     1.0\n",
      "5154468  138493  68319     1.0\n",
      "5154469  138493  40819     1.0\n",
      "5154470  138493  27311     1.0\n",
      "\n",
      "[5154471 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "# 1. Rating df 생성\n",
    "rating_data = \"/opt/ml/input/data/train/train_ratings.csv\"\n",
    "\n",
    "raw_rating_df = pd.read_csv(rating_data)\n",
    "raw_rating_df\n",
    "raw_rating_df['rating'] = 1.0 # implicit feedback\n",
    "\n",
    "raw_rating_df.drop(['time'],axis=1,inplace=True)\n",
    "\n",
    "print(\"Raw rating df\")\n",
    "print(raw_rating_df)\n",
    "\n",
    "# users = set(raw_rating_df.loc[:, 'user'])\n",
    "# items = set(raw_rating_df.loc[:, 'item'])\n",
    "\n",
    "# #2. Genre df 생성\n",
    "# genre_data = \"/opt/ml/input/data/train/genres.tsv\"\n",
    "\n",
    "# raw_genre_df = pd.read_csv(genre_data, sep='\\t')\n",
    "# raw_genre_df = raw_genre_df.drop_duplicates(subset=['item']) #item별 하나의 장르만 남도록 drop\n",
    "# # 장르 clustering 재정의\n",
    "# # print(raw_genre_df)\n",
    "\n",
    "# genre_dict = {genre:i for i, genre in enumerate(set(raw_genre_df['genre']))}\n",
    "# raw_genre_df['genre']  = raw_genre_df['genre'].map(lambda x : genre_dict[x]) #genre id로 변경\n",
    "# print(\"Raw genre df - changed to id\")\n",
    "# print(raw_genre_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>4643</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>170</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>531</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>616</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>2140</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5154466</th>\n",
       "      <td>138493</td>\n",
       "      <td>44022</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5154467</th>\n",
       "      <td>138493</td>\n",
       "      <td>4958</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5154468</th>\n",
       "      <td>138493</td>\n",
       "      <td>68319</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5154469</th>\n",
       "      <td>138493</td>\n",
       "      <td>40819</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5154470</th>\n",
       "      <td>138493</td>\n",
       "      <td>27311</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5154471 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         userID  itemID  rating\n",
       "0            11    4643     1.0\n",
       "1            11     170     1.0\n",
       "2            11     531     1.0\n",
       "3            11     616     1.0\n",
       "4            11    2140     1.0\n",
       "...         ...     ...     ...\n",
       "5154466  138493   44022     1.0\n",
       "5154467  138493    4958     1.0\n",
       "5154468  138493   68319     1.0\n",
       "5154469  138493   40819     1.0\n",
       "5154470  138493   27311     1.0\n",
       "\n",
       "[5154471 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_rating_df.columns = ['userID', 'itemID','rating']\n",
    "raw_rating_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = raw_rating_df\n",
    "# test = python_random_split(raw_rating_df, 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = raw_rating_df\n",
    "test = raw_rating_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Cornac Dataset\n",
    "\n",
    "To work with models implemented in Cornac, we need to construct an object from [Dataset](https://cornac.readthedocs.io/en/latest/data.html#module-cornac.data.dataset) class.\n",
    "\n",
    "Dataset Class in Cornac serves as the main object that the models will interact with.  In addition to data transformations, Dataset provides a bunch of useful iterators for looping through the data, as well as supporting different negative sampling techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 31360\n",
      "Number of items: 6807\n"
     ]
    }
   ],
   "source": [
    "train_set = cornac.data.Dataset.from_uir(train.itertuples(index=False), seed=SEED)\n",
    "\n",
    "print('Number of users: {}'.format(train_set.num_users))\n",
    "print('Number of items: {}'.format(train_set.num_items))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Train the BPR model\n",
    "\n",
    "The BPR has a few important parameters that we need to consider:\n",
    "\n",
    "- `k`: controls the dimension of the latent space (i.e. the size of the vectors  $w_u$  and  $h_i$ ).\n",
    "- `max_iter`: defines the number of iterations of the SGD procedure.\n",
    "- `learning_rate`: controls the step size $\\alpha$ in the gradient update rules.\n",
    "- `lambda_reg`: controls the L2-Regularization $\\lambda$ in the objective function.\n",
    "\n",
    "Note that different values of `k` and `max_iter` will affect the training time.\n",
    "\n",
    "We will here set `k` to 200, `max_iter` to 100, `learning_rate` to 0.01, and `lambda_reg` to 0.001. To train the model, we simply need to call the `fit()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpr = cornac.models.BPR(\n",
    "    k=NUM_FACTORS,\n",
    "    max_iter=NUM_EPOCHS,\n",
    "    learning_rate=0.01,\n",
    "    lambda_reg=0.001,\n",
    "    verbose=True,\n",
    "    seed=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:09<00:00,  4.50s/it, correct=87.70%, skipped=4.42%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization finished!\n",
      "Took 9.4526 seconds for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with Timer() as t:\n",
    "    bpr.fit(train_set)\n",
    "print(\"Took {} seconds for training.\".format(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BPR model is saved to testmodelsave.h5/BPR/2022-04-01_07-44-20-086430.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'testmodelsave.h5/BPR/2022-04-01_07-44-20-086430.pkl'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpr.save('testmodelsave.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = pickle.load(open('/opt/ml/Recommenders/testmodelsave.h5/BPR/2022-04-01_07-44-20-086430.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:09<00:00,  4.60s/it, correct=87.67%, skipped=4.41%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization finished!\n",
      "Took 9.2405 seconds for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with Timer() as t:\n",
    "    new_model.fit(train_set)\n",
    "print(\"Took {} seconds for training.\".format(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cornac.data.dataset.Dataset at 0x7fc0977f3e80>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Prediction and Evaluation\n",
    "\n",
    "Now that our model is trained, we can produce the ranked lists for recommendation.  Every recommender models in Cornac provide `rate()` and `rank()` methods for predicting item rated value as well as item ranked list for a given user.  To make use of the current evaluation schemes, we will through `predict()` and `predict_ranking()` functions inside `cornac_utils` to produce the predictions.\n",
    "\n",
    "Note that BPR model is effectively designed for item ranking.  Hence, we only measure the performance using ranking metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 248.3323 seconds for prediction.\n"
     ]
    }
   ],
   "source": [
    "with Timer() as t:\n",
    "    all_predictions = predict_ranking(bpr, train, usercol='userID', itemcol='itemID', remove_seen=True)\n",
    "print(\"Took {} seconds for prediction.\".format(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# with Timer() as t:\n",
    "#     seen_all_predictions = predict_ranking(bpr, train, usercol='userID', itemcol='itemID', remove_seen=False)\n",
    "# print(\"Took {} seconds for prediction.\".format(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19503"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_predictions[all_predictions['itemID']==8961])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5154471</th>\n",
       "      <td>11</td>\n",
       "      <td>8961</td>\n",
       "      <td>5.935120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5154472</th>\n",
       "      <td>11</td>\n",
       "      <td>1396</td>\n",
       "      <td>-0.469809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5154473</th>\n",
       "      <td>11</td>\n",
       "      <td>471</td>\n",
       "      <td>-2.465719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5154474</th>\n",
       "      <td>11</td>\n",
       "      <td>1042</td>\n",
       "      <td>0.387059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5154475</th>\n",
       "      <td>11</td>\n",
       "      <td>1947</td>\n",
       "      <td>-0.819334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213467515</th>\n",
       "      <td>138493</td>\n",
       "      <td>7753</td>\n",
       "      <td>-3.388236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213467516</th>\n",
       "      <td>138493</td>\n",
       "      <td>93422</td>\n",
       "      <td>-3.212936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213467517</th>\n",
       "      <td>138493</td>\n",
       "      <td>6519</td>\n",
       "      <td>-1.739218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213467518</th>\n",
       "      <td>138493</td>\n",
       "      <td>8830</td>\n",
       "      <td>-0.618888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213467519</th>\n",
       "      <td>138493</td>\n",
       "      <td>102880</td>\n",
       "      <td>-2.201961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>208313049 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           userID  itemID  prediction\n",
       "5154471        11    8961    5.935120\n",
       "5154472        11    1396   -0.469809\n",
       "5154473        11     471   -2.465719\n",
       "5154474        11    1042    0.387059\n",
       "5154475        11    1947   -0.819334\n",
       "...           ...     ...         ...\n",
       "213467515  138493    7753   -3.388236\n",
       "213467516  138493   93422   -3.212936\n",
       "213467517  138493    6519   -1.739218\n",
       "213467518  138493    8830   -0.618888\n",
       "213467519  138493  102880   -2.201961\n",
       "\n",
       "[208313049 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x7f365e5af4c0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttmp = temp.sort_values(by=[\"prediction\"]).groupby(\"userID\")\n",
    "ttmp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tttmp=pd.DataFrame(\n",
    "    data={\n",
    "        \"userID\": list(ttmp.groups.keys()),\n",
    "        \"itemID\": list(ttmp.itemID.apply(list)),\n",
    "        \"prediction\":list(ttmp.prediction.apply(list)),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>[2922, 2690, 91134, 7889, 4276, 107406, 110586...</td>\n",
       "      <td>[-8.578864097595215, -8.195862770080566, -7.61...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>[69784, 3272, 65225, 3761, 481, 67508, 6868, 6...</td>\n",
       "      <td>[-7.967667579650879, -7.656135559082031, -7.48...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>[1297, 8985, 108979, 2143, 83132, 8633, 37380,...</td>\n",
       "      <td>[-7.405815124511719, -7.285192012786865, -6.92...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>[30712, 8752, 26203, 3634, 109578, 5046, 6550,...</td>\n",
       "      <td>[-6.363016128540039, -5.6773295402526855, -5.6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31</td>\n",
       "      <td>[7486, 535, 1076, 2356, 52, 8044, 26704, 7396,...</td>\n",
       "      <td>[-6.797060489654541, -6.735404968261719, -6.34...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31355</th>\n",
       "      <td>138473</td>\n",
       "      <td>[5004, 4005, 5604, 4506, 26555, 5603, 6533, 46...</td>\n",
       "      <td>[-6.395918846130371, -6.344394207000732, -6.23...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31356</th>\n",
       "      <td>138475</td>\n",
       "      <td>[62376, 85056, 12, 1438, 2082, 798, 57353, 15,...</td>\n",
       "      <td>[-6.6155571937561035, -6.523186683654785, -6.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31357</th>\n",
       "      <td>138486</td>\n",
       "      <td>[26939, 5016, 66200, 48342, 31956, 28, 1365, 1...</td>\n",
       "      <td>[-7.121240139007568, -7.089005947113037, -6.49...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31358</th>\n",
       "      <td>138492</td>\n",
       "      <td>[5612, 52283, 54771, 51927, 31427, 3113, 47894...</td>\n",
       "      <td>[-6.9151997566223145, -6.4519219398498535, -6....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31359</th>\n",
       "      <td>138493</td>\n",
       "      <td>[101895, 3361, 7831, 4322, 7792, 88118, 79720,...</td>\n",
       "      <td>[-8.810928344726562, -7.791698455810547, -7.53...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31360 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       userID                                             itemID  \\\n",
       "0          11  [2922, 2690, 91134, 7889, 4276, 107406, 110586...   \n",
       "1          14  [69784, 3272, 65225, 3761, 481, 67508, 6868, 6...   \n",
       "2          18  [1297, 8985, 108979, 2143, 83132, 8633, 37380,...   \n",
       "3          25  [30712, 8752, 26203, 3634, 109578, 5046, 6550,...   \n",
       "4          31  [7486, 535, 1076, 2356, 52, 8044, 26704, 7396,...   \n",
       "...       ...                                                ...   \n",
       "31355  138473  [5004, 4005, 5604, 4506, 26555, 5603, 6533, 46...   \n",
       "31356  138475  [62376, 85056, 12, 1438, 2082, 798, 57353, 15,...   \n",
       "31357  138486  [26939, 5016, 66200, 48342, 31956, 28, 1365, 1...   \n",
       "31358  138492  [5612, 52283, 54771, 51927, 31427, 3113, 47894...   \n",
       "31359  138493  [101895, 3361, 7831, 4322, 7792, 88118, 79720,...   \n",
       "\n",
       "                                              prediction  \n",
       "0      [-8.578864097595215, -8.195862770080566, -7.61...  \n",
       "1      [-7.967667579650879, -7.656135559082031, -7.48...  \n",
       "2      [-7.405815124511719, -7.285192012786865, -6.92...  \n",
       "3      [-6.363016128540039, -5.6773295402526855, -5.6...  \n",
       "4      [-6.797060489654541, -6.735404968261719, -6.34...  \n",
       "...                                                  ...  \n",
       "31355  [-6.395918846130371, -6.344394207000732, -6.23...  \n",
       "31356  [-6.6155571937561035, -6.523186683654785, -6.4...  \n",
       "31357  [-7.121240139007568, -7.089005947113037, -6.49...  \n",
       "31358  [-6.9151997566223145, -6.4519219398498535, -6....  \n",
       "31359  [-8.810928344726562, -7.791698455810547, -7.53...  \n",
       "\n",
       "[31360 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tttmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5.27623987197876,\n",
       " 5.322011947631836,\n",
       " 5.36540412902832,\n",
       " 5.414576053619385,\n",
       " 5.418984413146973,\n",
       " 5.502008438110352,\n",
       " 5.890142440795898,\n",
       " 5.9291157722473145,\n",
       " 6.114536762237549,\n",
       " 7.077886581420898]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(\n",
    "#     tttmp[tttmp['userID']==11]['prediction']\n",
    "# )\n",
    "tttmp[tttmp['userID']==11]['prediction'].values[0][-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission = pd.DataFrame()\n",
    "u_ll=[]\n",
    "i_ll=[]\n",
    "for idx,row in tttmp.iterrows():\n",
    "    i_ll.append(row['itemID'][-10:])\n",
    "    u_ll.append(row['userID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(len(u_ll)==len(i_ll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_pd=pd.DataFrame(\n",
    "    data={\n",
    "        \"userID\": u_ll,\n",
    "        \"itemID\": i_ll,\n",
    "    }\n",
    ")\n",
    "submission = last_pd[[\"userID\", \"itemID\"]].explode(\n",
    "    \"itemID\", ignore_index=True\n",
    ")\n",
    "submission.to_csv(\"/opt/ml/Recommenders/bpr-epoch800-submission.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5154471</th>\n",
       "      <td>11</td>\n",
       "      <td>8961</td>\n",
       "      <td>5.365404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5154472</th>\n",
       "      <td>11</td>\n",
       "      <td>1396</td>\n",
       "      <td>-0.399799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5154473</th>\n",
       "      <td>11</td>\n",
       "      <td>471</td>\n",
       "      <td>-1.592354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5154474</th>\n",
       "      <td>11</td>\n",
       "      <td>1042</td>\n",
       "      <td>1.220800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5154475</th>\n",
       "      <td>11</td>\n",
       "      <td>1947</td>\n",
       "      <td>0.336741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         userID  itemID  prediction\n",
       "5154471      11    8961    5.365404\n",
       "5154472      11    1396   -0.399799\n",
       "5154473      11     471   -1.592354\n",
       "5154474      11    1042    1.220800\n",
       "5154475      11    1947    0.336741"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m k \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m----> 2\u001b[0m eval_map \u001b[38;5;241m=\u001b[39m \u001b[43mmap_at_k\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_predictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol_prediction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m eval_ndcg \u001b[38;5;241m=\u001b[39m ndcg_at_k(test, all_predictions, col_prediction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m'\u001b[39m, k\u001b[38;5;241m=\u001b[39mk)\n\u001b[1;32m      4\u001b[0m eval_precision \u001b[38;5;241m=\u001b[39m precision_at_k(test, all_predictions, col_prediction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m'\u001b[39m, k\u001b[38;5;241m=\u001b[39mk)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/recommenders/evaluation/python_evaluation.py:624\u001b[0m, in \u001b[0;36mmap_at_k\u001b[0;34m(rating_true, rating_pred, col_user, col_item, col_rating, col_prediction, relevancy_method, k, threshold)\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap_at_k\u001b[39m(\n\u001b[1;32m    583\u001b[0m     rating_true,\n\u001b[1;32m    584\u001b[0m     rating_pred,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    591\u001b[0m     threshold\u001b[38;5;241m=\u001b[39mDEFAULT_THRESHOLD,\n\u001b[1;32m    592\u001b[0m ):\n\u001b[1;32m    593\u001b[0m     \u001b[38;5;124;03m\"\"\"Mean Average Precision at k\u001b[39;00m\n\u001b[1;32m    594\u001b[0m \n\u001b[1;32m    595\u001b[0m \u001b[38;5;124;03m    The implementation of MAP is referenced from Spark MLlib evaluation metrics.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    621\u001b[0m \u001b[38;5;124;03m        float: MAP at k (min=0, max=1).\u001b[39;00m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 624\u001b[0m     df_hit, df_hit_count, n_users \u001b[38;5;241m=\u001b[39m \u001b[43mmerge_ranking_true_pred\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrating_true\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrating_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    626\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrating_pred\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrating_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcol_user\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcol_user\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcol_item\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcol_item\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcol_rating\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcol_rating\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcol_prediction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcol_prediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrelevancy_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelevancy_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[43m        \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    636\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m df_hit\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0.0\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/recommenders/evaluation/python_evaluation.py:81\u001b[0m, in \u001b[0;36m_check_column_dtypes.<locals>.check_column_dtypes_wrapper\u001b[0;34m(rating_true, rating_pred, col_user, col_item, col_rating, col_prediction, *args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_same_base_dtype(\n\u001b[1;32m     77\u001b[0m     rating_true, rating_pred, columns\u001b[38;5;241m=\u001b[39m[col_user, col_item]\n\u001b[1;32m     78\u001b[0m ):\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumns in provided DataFrames are not the same datatype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 81\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrating_true\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrating_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrating_pred\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrating_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcol_user\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcol_user\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcol_item\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcol_item\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcol_rating\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcol_rating\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcol_prediction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcol_prediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/recommenders/datasets/pandas_df_utils.py:483\u001b[0m, in \u001b[0;36mlru_cache_df.<locals>.decorating_function.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    481\u001b[0m args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m([to_pandas_hash(a) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m args])\n\u001b[1;32m    482\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {k: to_pandas_hash(v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m--> 483\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcached_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/recommenders/datasets/pandas_df_utils.py:448\u001b[0m, in \u001b[0;36mPandasHash.__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__hash__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;124;03m\"\"\"Overwrite hash operator for use with pandas objects\u001b[39;00m\n\u001b[1;32m    443\u001b[0m \n\u001b[1;32m    444\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;124;03m        int: hashed value of object\u001b[39;00m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 448\u001b[0m     hashable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpandas_object\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtobytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpandas_object, pd\u001b[38;5;241m.\u001b[39mDataFrame):\n\u001b[1;32m    450\u001b[0m         hashable \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpandas_object\u001b[38;5;241m.\u001b[39mcolumns)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "eval_map = map_at_k(test, all_predictions, col_prediction='prediction', k=k)\n",
    "eval_ndcg = ndcg_at_k(test, all_predictions, col_prediction='prediction', k=k)\n",
    "eval_precision = precision_at_k(test, all_predictions, col_prediction='prediction', k=k)\n",
    "eval_recall = recall_at_k(test, all_predictions, col_prediction='prediction', k=k)\n",
    "\n",
    "print(\"MAP:\\t%f\" % eval_map,\n",
    "      \"NDCG:\\t%f\" % eval_ndcg,\n",
    "      \"Precision@K:\\t%f\" % eval_precision,\n",
    "      \"Recall@K:\\t%f\" % eval_recall, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record results with papermill for tests\n",
    "sb.glue(\"map\", eval_map)\n",
    "sb.glue(\"ndcg\", eval_ndcg)\n",
    "sb.glue(\"precision\", eval_precision)\n",
    "sb.glue(\"recall\", eval_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. Rendle, S., Freudenthaler, C., Gantner, Z., & Schmidt-Thieme, L. (2009, June). BPR: Bayesian personalized ranking from implicit feedback. https://arxiv.org/ftp/arxiv/papers/1205/1205.2618.pdf\n",
    "2. Pan, R., Zhou, Y., Cao, B., Liu, N. N., Lukose, R., Scholz, M., & Yang, Q. (2008, December). One-class collaborative filtering. https://cseweb.ucsd.edu/classes/fa17/cse291-b/reading/04781145.pdf\n",
    "3. **Cornac** - A Comparative Framework for Multimodal Recommender Systems. https://cornac.preferred.ai/"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
